= Beep: The microservice way
Hugo Ponthieu <hugopont08@gmail.com>
:description: Redefine the architecture of the Beep application
:keywords: beep, architecture, microservices, keycloak, grpc, rust, monitoring, backuping
:doctype: acticle
:sectnums:
:toc: 
:title-page:
:pdf-fontsize: 12

[abstract]
== Abstract

Beep is a chat application that allows users to communicate with each other in real-time.
The goal of this document is to provide an overview of the architecture of the application, including the services, protocols, and security mechanisms used to build the application.

Currently the application is developed in a monolithic way. As the features grow, the application is harder to maintain and scale. In fact, all the elements of the application can only be scaled together. Futhermore,  the application is not fault tolerant, if a service fails, the whole application will be down.

Those outage can be caused by high loads or network issues. It can also come from the development team that can introduce bugs in the application. The decoupling of responsibilities that offer microservices architecture will help to reduce the impact of a single component failure and let us to scale the application more easily.

== Application Overview

=== Current features

**Chatting via channels**: Users can create channels and send messages to each other. They can also create private channels to communicate with their friends.

**Servers**: Server are the main entity of the application. They regroup users and channels. A user can be part of multiple servers. A server can have multiple channels. 
Inside, allowed users can communicate with each other or define roles.
Web

=== End-user capabilities

To better design and implement the application, we will need to define the capabilities of the users. With the needs of client in mind, we will be able to define parts of the application that can be separated.

But also we will be able to define any point of dependency between the services. This will allow us to define potential interactions between the services.

We will try to define the capabilities of the user by making it impersonate different characters. There will be characters based on the authorization level of the user: 
- Guest user: A user that is not authenticated
- User: A user that is authenticated

But also on more fine grained authorization level:
- UserModerator: A user that can perform some actions on the users
- ServerModerator: A user that can perform manage the server of the application

And of course there will be more fined grained authorization on resources that we will define along with the capabilities of the user.

==== Account

We will begin like if a user just discrovers the application. He will be able to access the application as a guest user.

As a guest user I want to be able to sign up using:

- My email and password
- My google account
- My Polytech account 

The users that are sign up will have the abilitie to authenticate and access the application only once their account is validated.

As a user:

- I want to be able to sign in using the same methods as the sign up in order to access the application.
- that is sign in with my email and password I want to be able to link my google account to my account so that I can later authenticate with it.
- I want to change my password in order to secure my account.
- I want to be able to delete my account in order to leave the application.

Once the user is authenticated he will be able to access the application. 
Therefore we will focus now more on action that he can perform on his profile information.

As a user:

- I want to be able to update my profile information such as my name, last name, nickname and profile picture in order to keep it up to date.
- I want to be able to change my email in order to transfer my account to another email.
- I want to be able to change my password in order to secure my account.
- I want to be able to activate Two-Factor Authentication in order to secure my account.
- I want to be able to deactivate Two-Factor Authentication in order to secure my account.
- I want to be able to delete my account in order to leave the application.

[red]#NOTE: USE CASE DIAGRAM#

==== Social

Once authenticated the user will be able to access some features without any further authorization. He will be able to access the friends system.
We can first focus on the friend management for a given user.

As a user I want to:

- invite a user from their username to add a friend. 
- list the invitations that I have sent or that other user sent me in order to manage them.
- accept a friend request in order to connect with the user.
- decline a friend request.
- cancel a friend request that I have sent in order to not have the user as friend.

Once I am friend with a user I want to be able to manage my frienship.

As a user I want to:

- list my friends in order to see who are my friends.
- remove a friend in order to not have him as friend anymore.

In order to regroup users, users be members of servers. There are 2 types of servers, public and private. 
The user can join a public server without any authorization. 
But he will need to be invited to join a private server.
So as a user I want to:

- see all the public servers in order to join them.
- see all the servers that I am member of in order to manage them.
- leave server so that I am not related to it anymore.
- be able to answer to a server invitation so I can be a member of a server.
- browse the servers by their name and description so I can find the communities that I want to join.

[red]#NOTE: USE CASE DIAGRAM#

==== Chatting

As user discover other users, he will want to interact with them. He will be able to do that through the chat system.
It is composed of channel that contain messages. We will see in that part what are the abilities.
As a user I want to: 

- create a channel to be able to communicate with other users.
- delete a channel in order to not have it anymore.
- list the channels that I am part of in order to manage them.
- join a channel in order to communicate with the users.
- leave a channel in order to not be part of it anymore.
- add a user to a channel in order to let him communicate with the users.
- to search thrgouh the entire messages of a channel to find a message based on a keyword


With access to a channel the user will want to discuss with other users. 
As a user I want to:

- send a message in a channel in order to communicate with the users.
- send files in a message in order to share them with the users.
- delete a message so that I clean a channel.
- edit a message in order to correct it.
- list the messages of a channel in order to see the history of the channel.
- to pin messages in a channel to keep them visible for long time.

[red]#NOTE: USE CASE DIAGRAM#

==== Severs

As cited before the user will be able to join servers. They regroup users and channels.
A user that is authenticated and that as access to a particular server is called a member of the server.

By default a member will not perform any action on the server. He will need to be granted with a role to perform some actions. Role are defined at the server level and they will be aggregation of more fine-grained role.

The fine-grained roles will be:

- administrator
- server manager 
- role manager
- channel manager
- channel viewer
- webhook manager
- nickname manager
- nickname changer
- message sender
- message manager
- file attacher
- member manager
- invitation manager

As invitation manager I want to:

- invite a user to a server in order to let him join the server.
- create an invitation in order to let users join the server.
- choose the expiration date of an invitation in order to manage the invitations.

As a member manager I want to:

- add a role to a member so they can perform specific actions.
- remove a role from a member to prevent them from performing certain actions.
- list the members of a server to manage them effectively.
- temporarily mute members to restrict them from sending messages.
- ban members to prevent them from joining the server.
- kick members to remove them from the server.

As a role manager I want to:

- create a role to define user permissions.
- update a role to modify user permissions.
- delete a role to remove it from the system.
- list the roles of a server to manage them.
- assign roles to members to enable them to perform specific actions.
- remove roles from members to restrict their actions.

As a nickname manager I want to:

- update the nickname of a member to change their display name.
- change my own nickname to update my display name.

As a nickname changer I want to:

- change my own nickname to update my display name.

As a channel manager I want to:

- create a channel to enable users to communicate.
- update a channel to modify its settings.
- delete a channel to remove it from the server.
- list the channels of a server to manage them.
- restrict permissions of user or role on a channel to control user actions.

As a channel viewer I want to:

- list the messages of a channel to view the conversation.
- search for messages in a channel to find specific information.
- list channel of a server to find the channel I want to see the conversation of.

As a message sender I want to:

- send a message in a channel to communicate with other users.
- update a message to correct it.

As a message manager I want to:

- delete a message to remove it from the channel.
- pin a message to keep it visible in the channel.
- perform same action as the message sender.

As a file attacher I want to:

- attach a file to a message to share it with other users.

As a server manager I want to:

- update the server settings to modify its configuration.
- delete the server to remove it from the system.
- perform the same action as the channel manager.

As an administrator I want to:

- perform all actions on the server to manage it effectively.

[red]#NOTE: USE CASE DIAGRAM#

==== Administration

With the affluence of users, the application will need to be managed. The administration of resource will be done by different type of admin.
This time role will be directly associated to the users.

Roles will be:

- UserModerator
- ServerModerator
- ApplicationAdministrator

== Global Architecture

=== Presentation 


=== Schema

.Overview of the application
image::services/beep-application_diagramme.svg[]

=== Security

==== Authentication

link:https://github.com/hugoponthieu/beep-front[Frontend integration of keycloak]

link:https://github.com/hugoponthieu/beep-api[Backend integration of keycloak]

===== Introduction

Authentication is a critical aspect of any microservices architecture. 
In this document, we will discuss how to integrate Keycloak for authentication to enforce authentication policies at the gateway level.

===== Keycloak Overview

Keycloak is an open-source identity and access management solution. It provides features such as single sign-on (SSO), user federation, and social login. 
Keycloak is a suitable choice for our application due to its robust authentication capabilities and ease of integration with microservices.

As the user should be able to authenticate with their email and password, with their google account and their Polytech account from an LDAP Keycloak is suited for this task.

The service allow the user to authenticate natively from frontend implementation by exposing the login page of Keycloak. The user will be able to authenticate with their email and password, with their google account and their Polytech account from an LDAP.


[red]#NOTE: SCREENSHOT OF THE KEYCLOAK GOOGLE#
[red]#NOTE: AUTHENTICATION WORKFLOW SEQUENCE DIAGRAM#

It will take the responsability to:

- Register new users in the application
- To issue tokens the user through diverser methods (email, google, LDAP)
- To check the validity of a token


===== OAuth2 Overview
OAuth2 is an authorization framework that allows applications to securely obtain limited access to user accounts on an HTTP service by delegating authentication to a centralized identity provider, such as Keycloak.

**Authorization Code Flow**: This flow is suitable for applications that can securely store client secrets. It involves exchanging an authorization code for an access token.


===== In our architecture

For example if a user wants to access a resource on a service, the service will redirect the user to the authorization server (Keycloak) to authenticate the user. Once the user is authenticated, the server will issue an access token to the user, which can be used to access the resource. This token is short-lived and can be revoked at any time, providing an additional layer of security.

From the access token the user will be able to access the service. To enforce the check of the access token the service will use the introspection endpoint of the authorization server.

[red]#NOTE: SEQUENCE WORKFLOW FOR THE GATEWAY#

We have to note that all service will have an upstream gateway that will check the access token of the user before forwarding the request to the service. This will ensure that only authenticated users can access the services.

Although the user will maybe need to be known by the service, in order to perform some actions. For example, getting the the list of its friends or direct messages.
In that case the service will access directly the authorization server to get the user information.


===== End-user authentication

The user will be able to authenticate with their email and password, with their google account and their Polytech account from an LDAP.

If the users try to access to the frontend wit

===== Deployment

[red]#NOTE: DEPLOYMENT SCHEME FOR THE KEYCLOAK IN CLUSTER#


==== Authorization

Authorization is a critical aspect of any microservices architecture. In this document, we will discuss how to implement role-based access control (RBAC) within servers and global roles in our application. 

===== Roles

Roles in the application are categorized into two types:

- **Global Roles**: Defined at the application level, these roles apply across all services and enforce high-level access control policies (e.g., `admin`, `moderator`, `user`).

- **Server Roles**: Defined at the server level, these roles are specific to individual servers and manage permissions within that context.

Both types of roles will be used to implement fine-grained access control policies.

===== Permify

Permify implement Authorization as a Service. It will be used to manage the roles and the permissions of the users.

Permify exposes an REST and a GRPC api that contain the same endpoints. We will use the GRPC api to communicate with the service as it is lighter for communication between services.

When performing an action on a resource, the service will check if the user has the required role to perform the action. This is a purely binary response, either the user is allowed or not.

====== Data management

Permify hold the data in a Postgres database. It will be used to store the roles and the permissions of the users.
We will therefore need to replicates the data in the Permify database.

We will develop a service that hold the logic that can be used to manage the data in the Permify database. This service will be callable with a GRPC api.
This service will be called when the following operation are performed:
- a user join a server
- a user leave a server
- a user is assigned a Server-wide & Application-wide role 
- a user is removed from a Server-wide & Application-wide role
- a user is muted
- a user is unmuted
- a user is banned
- a user is kicked

The service will therefore hold the data and will be able to enforce the rules on the data.

== Implementation

=== Deployment

=== Networking

Microservices implies some networking constraints such as securing a flow of data between services, managing the load of the services, and ensuring the availability of the services.

For that task we will use Istio as a service mesh. It will allow us to manage the networking of the services in a more efficient way.

==== Service Mesh Overview

A service mesh is a dedicated infrastructure layer that provides service-to-service communication, observability, and security for microservices applications. It abstracts the network and provides a set of features that simplify the development and operation of microservices.

Service mesh provides the following benefits:

- Traffic management: control the flow of traffic between services, implement routing rules, and perform load balancing.
- Security: provides encryption, authentication, and authorization to secure communication between services.
- Observability: provides metrics, logging, and tracing to monitor the performance and health of services.

==== Istio Overview

Istio is an open-source implementation of a service mesh that provides advanced networking features for microservices applications. 
It integrates with Kubernetes and provides a set of tools to manage service-to-service communication, security, and observability.

One of the key advantages of using Istio is that it is actively developed and maintained by a well-known and reputable community. This ensures that the project remains up-to-date with the latest features, security patches, and best practices. As a result, Istio is a reliable and robust choice for a microservices project that is intended to last over time.

One of the main component of Istio is the data plane that will be used to manage the traffic between the services.
It will be composed of Envoy proxies that will be deployed alongside the services.
All the traffic coming and leaving a pod is redirected to the Envoy proxy that will manage the traffic.
This will allow to implement a lot of traffic related features such as load balancing, retries, timeouts, and circuit breaking. 

Via proxies Istio is capable to log, trace and monitor natively and seamlessly  the traffic between the services. This will allow to have a better observability of the application.

As describe, Istio will allow us to manage a lot of constraints outside of the services and let the services focus on their core functionalities. 
It is really suitable to delegate the networking constraints to a dedicated service that will manage them in a more efficient way.

==== mTLS (Mutual TLS)

Mutual Transport Layer Security (mTLS) is a security protocol that provides encryption, authentication, and integrity for communication between services. 
It ensures that only trusted services can communicate with each other and that the data exchanged between services is secure.

In our application, we will use mTLS to secure communication between services and prevent unauthorized access to sensitive data. By enabling mTLS, we can ensure that all communication between services is encrypted and authenticated, reducing the risk of data breaches and unauthorized access.

Istio provides built-in support for mTLS and makes it easy to enable mTLS for all services in the mesh.

[red]#NOTE: SCHEME OF THE PROXIES WITH MTLS#

==== Gateway and Securing with TLS

Istio Gateway is a component that manages inbound and outbound traffic for services in the mesh. It acts as an entry point for external traffic and provides features such as load balancing, routing, and security.

In our application, we will use Istio Gateway to manage external traffic and secure communication with clients.
By configuring Istio Gateway with Transport Layer Security (TLS), we can encrypt traffic between clients and services, ensuring that data is secure in transit.

Istio Gateway provides built-in support for TLS and makes it easy to configure TLS settings for services in the mesh. 
By enabling TLS on Istio Gateway, we can secure communication with clients and protect sensitive data from eavesdropping and tampering.

[red]#NOTE: SCHEME OF THE GATEWAY#

==== Circuit Breaking

Circuit breaking is a design pattern that prevents cascading failures in distributed systems. 
It works by monitoring the health of services and breaking the circuit if a service becomes unresponsive or slow.

In our application, we will use circuit breaking to ensure service reliability and prevent service degradation. 
By implementing circuit breaking in Istio, we can detect and isolate failing services, preventing them from affecting other services in the mesh.


[red]#NOTE: SCHEME CIRCUIT BREAKING#


=== Protocols

link:https://github.com/hugoponthieu/hello-transport[Poc grpc with rust]

==== Overview of Protocols

Protocols are a fundamental component of microservices architecture, dictating the mechanisms by which services interact and exchange data. 
This section delves into the technical intricacies of various protocols, including REST, gRPC, and GraphQL, and elucidates the rationale behind selecting gRPC for our application.

HTTP/1.1, commonly used for RESTful APIs, is advantageous due to its simplicity, widespread adoption, and ease of implementation. 
It supports complex REST APIs and is inherently compatible with web browsers. 
However, it suffers from several limitations: the lack of type safety, verbosity of JSON payloads, and suboptimal performance due to the overhead of HTTP headers and the text-based JSON format. 
Despite these drawbacks, REST APIs can be secured using HTTPS with TLS (Transport Layer Security), ensuring encrypted communication.

REST APIs benefit from self-discoverability through OpenAPI specifications, which facilitate seamless integration and collaboration among microservices developed by disparate teams. 
This discoverability is crucial in a microservices ecosystem where services must interoperate efficiently.

gRPC's strong typing and contract-first approach, enforced through .proto files, ensure consistency and reliability in inter-service communication. 
This is particularly beneficial in large-scale microservices architectures where maintaining compatibility and preventing breaking changes are paramount.


Given the technical requirements of our application, including the need for efficient, low-latency communication and strong typing, we have chosen gRPC as the primary protocol for inter-service communication. 
gRPC's performance advantages, coupled with its robust type safety and support for bi-directional streaming, make it an ideal choice for our microservices architecture.

In summary, while REST have its merits, gRPC's technical superiority in terms of performance, efficiency, and type safety aligns with the demands of our application, ensuring reliable and scalable inter-service communication.

// GraphQL, another protocol, provides a flexible query language for APIs, allowing clients to request precisely the data they need. 
// While powerful, GraphQL introduces complexity in terms of query parsing and execution, and may not be as performant as gRPC for certain use cases, particularly those involving high-throughput, low-latency communication.

==== gRPC

Remote Procedure Call (RPC) is a protocol that one program can use to request a service from a program located on another computer in a network. It allows a program to execute a procedure (subroutine) in another address space (commonly on another physical machine). The calling program is suspended until the remote procedure returns, and the remote procedure executes in a different address space. RPC abstracts the communication between the client and server, making it appear as if the procedure call is local.

gRPC is a high-performance, open-source RPC framework developed by Google. It uses Protocol Buffers (protobuf) as the interface definition language (IDL) and leverages HTTP/2 for transport. gRPC offers several advantages over traditional RESTful APIs, including:

- Speed: Faster than REST due to HTTP/2, which allows multiple requests at once, compresses headers, and supports server push.
- Strong typing: Uses protobuf for data, ensuring messages are consistent and efficient.
- Real-time: Supports two-way streaming, letting clients and servers send multiple messages in real-time.
- Multi-language: Works with many programming languages, making it easy to build services in different languages.

==== Inter-service communication

image::communication/beep-server-creation.svg[][]

==== Client communication

=== Services


==== Users 

The user service is responsible for managing user accounts, including registration, authentication, and profile management. It handles user-related operations such as creating, updating, and deleting user accounts.
It also manages user preferences, settings, and security features like password resets and two-factor authentication.
It will expose a REST API for user management and a gRPC API for inter-service communication.

The user service will rely on Keycloak. In fact all the data will be stored in the Keycloak database. and we will use the Keycloak API to manage the users.

Therefore keycloak will be hold the datas for the all the users of the application. And all the services will enforce the authentication of users through the Keycloak API.

Keycloak will rely on a Postgres database to store the data.

[red]#NOTE: SCHEMA OF THE KEYCLOAK DATABASE#


==== File storage

The file storage service is responsible for managing file uploads and downloads. It handles file-related operations such as uploading, downloading, and deleting files.
It will expose a REST API for file management and a gRPC API for inter-service communication.
The file storage service will rely on a Minio server to store the files. Minio is an open-source object storage server that is compatible with Amazon S3. It provides a simple and efficient way to store and retrieve files.
The file storage service will use the Minio API to manage the files. It will store the files in a Minio bucket and provide a URL for each file that can be used to access it.
[red]#NOTE: SCHEMA OF THE MINIO DATABASE#

Each service will have its own path to store the files. The file storage service will use a unique prefix for each service to avoid conflicts. For example, the user service will store files in the `user` prefix, while the message service will store files in the `message` prefix.

==== Servers 

A lot of objects have strong relation with servers. That is why the server service will be responsible for managing servers,members, roles, channels, and webhooks.
The server service will use postgres to store the data. It will expose a REST API for server management and a gRPC API for inter-service communication.

This service will be responsible for writing the data in the Permify database. It will be called when the following operation are performed a user:
- join a server
- leave a server
- is assigned a Server-wide & Application-wide role
- is removed from a Server-wide & Application-wide role
- is muted
- is unmuted
- is banned
- is kicked
- is invited to a server
- is removed from a server
- is assigned a role in a server

The service will do a lot of call to the Permify service to check if the user is allowed to perform the action.

A channel can be linked to a server. Otherwise it will be a direct message channel.
Inside a server, a channels can have multiple types:

- text channel: a simple channel to send messages in
- conference channel: a channel where authorized users can join a voice channel to communicate with each other
- thread: a thread is a sub-channel of a channel. It allows users to discuss a specific topic without cluttering the main channel. Threads can be created within text channels by referencing a message. 
- category: a category is a way to group channels together. It allows users to organize their channels and make it easier to find them. Categories can be created within servers and can contain multiple channels.

In a server, the authorized users can create role with different permissions: 
- administrator: will inherit all the permissions of the server
- server manager: can perform all the actions on the server
- role manager: can perform all the actions on the roles and add people to roles
- channel manager: can create all kind of channels and manage the channels
- channel viewer: can see the channels and the messages of the channels
- webhook manager: can create webhooks to send messages to other services
- nickname manager: can manage the nicknames of the users


Those permission can be assigned to a role and the role to a member of the server.

==== Messages & Search 

The message service is responsible for managing messages in channels. It handles message-related operations such as sending, receiving, and deleting messages.
It also manages message history, search functionality, and webhooks for real-time notifications.
It will expose a REST API for message management and a gRPC API for inter-service communication.
The message service will do not need all lot of relation constraint. It will be able to store the messages in a NoSQL database.

The message service rely on a MongoDB database to store the messages. MongoDB is a NoSQL database that provides a flexible and scalable way to store and retrieve data. It is well-suited for storing messages and allows for efficient querying and indexing.

MongoDB provide rich features for indexing and performing full-text search.
The indexation will be done on the file name if the message contains a file and on the content of the message. 

[source,go]
----
type File struct {
	ID         primitive.ObjectID `bson:"_id,omitempty"`
	Filename   string             `bson:"filename"`
	Mimetype   string             `bson:"mimetype"`
	Size       int64              `bson:"size"`
	StorageKey string             `bson:"storageKey"`
	UploaderID primitive.ObjectID `bson:"uploaderId"`
	UploadDate time.Time          `bson:"uploadDate"`
}

type Message struct {
	ID          primitive.ObjectID   `bson:"_id,omitempty"`
	SenderID    primitive.ObjectID   `bson:"senderId"`
	ChannelID   primitive.ObjectID   `bson:"channelId"`
	Content     string               `bson:"content"`
	CreatedAt   time.Time            `bson:"createdAt"`
	Attachments []primitive.ObjectID `bson:"attachments"`
}
----

In the case a user want perform search in one channel, could be a direct message channel or a server channel, we will only need to filter the messages by the channel id.

In the case a user want to perform a search in all the channels of a server, we will need to filter the messages by asking all the channels the user has access on the server.

[red]#NOTE: Detail the link to the s3 files#

Also messages will be able to hold a link to a file to manage the attachments. This url will only be a link to the file in the subdirectory dedicated to the message service.

[red]#NOTE: Detail the link to the s3 files#


==== Authorization

The authorization service will hold the logic that can be used to manage the data in the Permify database. This service will be callable with a GRPC api.
Permify leverages a Postgres database to store the data. It will be used to store the roles and the permissions of the users.

.Create a message in a channel of a server and check the authorization
image::security/sequence_auth.png[]

Other services will need to store the data in the Permify database. This service will be called when the following operation are performed. Therefore permify will be able to enforce the rules on the data.
Only then all the services in the application will be able to verify requests against the data in the Permify database.

==== Voice channel communication


=== Deployment

All services will be deployed across multiple Kubernetes clusters to improve fault tolerance and ensure high availability. Each service will reside in its own namespace, allowing for independent resource management. 
The clusters will be deployed on Virtual Machines (VMs) to provide flexibility and scalability. We will use Proxmox VE as the hypervisor to manage the VMs, allowing us to create and manage multiple virtual machines on a single physical server.

==== Kubernetes

The entire infrastructure will run on Kubernetes, divided into two clusters: one for services and another for databases. Services will be isolated within their own namespaces to ensure independent resource management and high availability. Helm charts will facilitate deployment by simplifying configuration, packaging, and dependency handling.

The clusters will be deployed on Virtual Machines with the Talos linux distribution. Talos is a modern, immutable Linux distribution designed specifically for Kubernetes. It provides a lightweight and secure environment for running Kubernetes clusters, making it an ideal choice for our application.

The cluster dedicated for services will expose listen for traffic on port 443 for HTTPS and port 80 for HTTP. It will allow the user to access the web application and the API. 

In order to provide a high availability of the application, we will deploy 3 control nodes per cluster which is the link:https://www.siderolabs.com/blog/why-should-a-kubernetes-control-plane-be-three-nodes/[recommended configuration by Talos maintainers].
The control plane nodes will be responsible for managing the Kubernetes cluster and ensuring that the services are running smoothly.

The worker nodes will be responsible for running the services and the databases. For the databases, we want to ensure a high availability and fault tolerance.
We will deploy 3 worker nodes per cluster. This will allow us to have a high availability of the services and the databases. We will see later how to leverage the Kubernetes operators to manage the databases and high availability.

In order to increase the fault tolerance we will use longhorn to manage the storage of the services. Longhorn is a cloud-native distributed block storage solution for Kubernetes. It allows to the replication of the data across multiple nodes. Also it provides tools to backup the kubernetes volumes and to restore them in case of failure.

==== Packaging, deploying services

Each service will be packaged as a Docker image, allowing for easy deployment and scaling. The images will be stored in a private Docker registry to ensure security and control over the deployment process.
Then the images will be deployed to the Kubernetes cluster using Helm charts. Helm charts will simplify the deployment process by providing a standardized way to package and deploy applications on Kubernetes.
All the charts of the services will be stored inside a registry dedicated to the charts.

We will use a GitOps approach to manage the deployment of services. This means that all the configuration files and Helm charts will be stored in a Git repository. That is why it is important to have convention for the naming of the docker images. 
We will use the SemVer convention for the naming of the docker images such as `beep-api:1.0.0`. 

.SemVer Overview
Semantic Versioning (SemVer) is a versioning scheme for software that conveys meaning about the underlying changes. A version number is structured as `MAJOR.MINOR.PATCH`:

- **MAJOR**: Incremented when incompatible API changes are introduced.
- **MINOR**: Incremented when functionality is added in a backward-compatible manner.
- **PATCH**: Incremented when backward-compatible bug fixes are made.

For example:
- `1.0.0`: Initial stable release.
- `1.1.0`: Adds new features in a backward-compatible way.
- `1.1.1`: Fixes bugs without breaking existing functionality.

By adhering to SemVer, we ensure clear communication of changes and compatibility between versions, which is critical for managing microservices in a distributed architecture.

==== Deploying databases

We will deploy databases in a separate Kubernetes cluster to ensure isolation and security. 
Even though it is often advised to deploy databases on bare metal instances, Kubernetes provides a flexible and scalable environment for managing databases. Futhermore, a lot of tools are available to manage databases in Kubernetes.
Each database will be deployed using a Kubernetes operator, which simplifies the management and scaling of databases in a Kubernetes environment.

A lot of databases will be used in the application. And they all provide a way kubernetes operator to deploy the database:

- link:https://github.com/mongodb/mongodb-kubernetes-operator/blob/master/README.md[MongoDB Community Operator]
- link:https://cloudnative-pg.io/[Postgres Operator]
- link:https://min.io/docs/minio/kubernetes/upstream/operations/installation.html[Minio Operator]

Some services will need some cache. For that we will use the link:https://operatorhub.io/operator/redis-operator[Redis operator].

Each instance of databases will be deployed on it's own kubernetes node.

In order to scale the databases and allow high availability, we will use the following configuration:

- MongoDB: 3 replicas with sharding enabled
- Postgres: 3 replicas with streaming replication enabled
- Minio: 3 replicas with erasure coding enabled
- Redis: 3 replicas with clustering enabled

We will need:
- Each database 

==== ArgoCD

ArgoCD is a declarative, GitOps continuous delivery tool for Kubernetes. It allows us to manage the deployment of applications and services in a Kubernetes cluster using Git as the source of truth.
ArgoCD will be used to manage the deployment of services and databases in the Kubernetes cluster. 
It will monitor the Git repository for changes and automatically deploy the updated configuration to the cluster. 
This ensures that the deployment process is consistent and repeatable, reducing the risk of errors and improving reliability.

The instance will be deployed in the Kubernetes cluster that will host the databases.

We will store all the configuration values.yaml files of the services in a Git repository. Each services will have its own folder in the repository. The values file will contain the version of the docker image to deploy and the configuration values of the service:

```yaml
image:
  repository: beep-api
  tag: 1.0.0
```

When a service is updated, a pipeline will be triggered to build the Docker image and push it to the Docker registry. 
The pipeline will also update the values.yaml file in the Git repository with the new version of the Docker image. As ArgoCD is monitoring the Git repository, it will automatically deploy the updated configuration to the Kubernetes cluster.


=== Clusters  

As described before, we will  need to deploy two kubernetes clusters. One for the services and one for the databases.




=== Monitoring
==== Alerting
==== Logging
==== Tracing

=== Backuping


